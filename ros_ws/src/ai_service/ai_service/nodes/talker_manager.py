import os
from dotenv import load_dotenv
import socket
import threading
import queue
import struct
import numpy as np
import pvporcupine
import resampy
import openai
import time
import speech_recognition as sr
from datetime import datetime
import pytz
from google.cloud import texttospeech
import wave
import sys

# ================== í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¸íŒ… ==================
# í˜„ì¬ ì‹¤í–‰ ê²½ë¡œì—ì„œ ros-repo-1 ìœ„ì¹˜ ì°¾ê¸°
current_path = os.path.abspath(os.path.dirname(__file__))
print(f"í˜„ì¬ ê²½ë¡œ: {current_path}")

# ros_wsì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ ê·¸ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì„¤ì •
ros_ws_index = current_path.find('/ros_ws/')
if ros_ws_index != -1:
    PROJECT_ROOT = current_path[:ros_ws_index]
else:
    # ë°±ì—… ë°©ë²•: í˜„ì¬ ìœ„ì¹˜ì—ì„œ ìƒìœ„ë¡œ ì˜¬ë¼ê°€ë©° ì°¾ê¸°
    PROJECT_ROOT = os.path.abspath(os.path.join(current_path, '../../../../../../'))

print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ: {PROJECT_ROOT}")
env_path = os.path.join(PROJECT_ROOT, '.env')
print(f".env íŒŒì¼ ê²½ë¡œ: {env_path}")

# íŒŒì¼ ì¡´ì¬ í™•ì¸
if not os.path.exists(env_path):
    raise FileNotFoundError(f".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")

load_dotenv(dotenv_path=env_path)

# ================== í™˜ê²½ ë³€ìˆ˜ ë° ëª¨ë¸ ê²½ë¡œ ==================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PICOVOICE_ACCESS_KEY = os.getenv("PICOVOICE_ACCESS_KEY")

if not all([OPENAI_API_KEY, PICOVOICE_ACCESS_KEY]):
    raise ValueError("OPENAI_API_KEY ë˜ëŠ” PICOVOICE_ACCESS_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤!")

DATA_DIR = os.path.join(PROJECT_ROOT, 'data')

# Google Cloud ì¸ì¦ í‚¤ ì„¤ì • (ì§ì ‘ íŒŒì¼ ì‚¬ìš©)
GOOGLE_CREDS_PATH = os.path.join(DATA_DIR, 'fleet-unison-452704-j5-31aaeff5ac33.json')
if not os.path.exists(GOOGLE_CREDS_PATH):
    raise FileNotFoundError(f"Google Cloud ì¸ì¦ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {GOOGLE_CREDS_PATH}")

# Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¸ì¦ íŒŒì¼ ì§ì ‘ ì‚¬ìš©)
tts_client = texttospeech.TextToSpeechClient.from_service_account_file(GOOGLE_CREDS_PATH)

PORCUPINE_MODEL_PATH = os.path.join(DATA_DIR, 'porcupine_params_ko.pv')
PORCUPINE_KEYWORD_PATH = os.path.join(DATA_DIR, 'riboya_ko_linux_v3_0_0.ppn')

for path in [PORCUPINE_MODEL_PATH, PORCUPINE_KEYWORD_PATH]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

# ================== ë„¤íŠ¸ì›Œí¬/ì˜¤ë””ì˜¤ ê¸°ë³¸ ì„¤ì • ==================
HAEDWARE_HANDLER_IP = "127.0.0.1"       # Hardware Handler IP
AI_SERVICE_IP = "127.0.0.1"            # AI Service IP
MIC_STREAM_PORT = 7000                 # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ í¬íŠ¸ (UDP)
SPEAKER_PORT = 7002                    # ìŠ¤í”¼ì»¤ ì¶œë ¥ í¬íŠ¸ (TCP)
NATIVE_RATE = 48000                    # mic_streamerì™€ ë™ì¼ int16
TARGET_RATE = 16000                    # ì›¨ì´í¬ì›Œë“œ ì²˜ë¦¬ìš©
TTS_RATE = 24000                      # TTS ì¶œë ¥ ë ˆì´íŠ¸
CHANNELS = 1
CHUNK = 2048                           # mic_streamerì™€ ë™ì¼

# TCP ì„œë²„ ì„¤ì •
tcp_server = None
tcp_client = None

# ================== UDP/TCP í†µì‹  ê´€ë¦¬ ==================
def get_kr_time():
    kr_tz = pytz.timezone('Asia/Seoul')
    return datetime.now(kr_tz).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]  # ë°€ë¦¬ì´ˆ 3ìë¦¬ê¹Œì§€ í‘œì‹œ

class CommunicationManager:
    def __init__(self):
        self.udp_sock = None
        self.tcp_server = None
        self.tcp_client = None
        self.buffer_queue = queue.Queue()
        self.stop_event = threading.Event()
        self.tcp_ready = threading.Event()

    def start_udp_receiver(self):
        """UDP ìˆ˜ì‹ ê¸° ì´ˆê¸°í™” ë° ì‹œì‘"""
        def _udp_receiver():
            try:
                self.udp_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                self.udp_sock.bind((HAEDWARE_HANDLER_IP, MIC_STREAM_PORT))
                print(f"[{get_kr_time()}][UDP] ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘... ({HAEDWARE_HANDLER_IP}:{MIC_STREAM_PORT})")
                
                received_count = 0
                start_time = time.time()
                
                while not self.stop_event.is_set():
                    data, _ = self.udp_sock.recvfrom(CHUNK * 2)
                    self.buffer_queue.put(data)
                    received_count += 1
                    
                    if received_count % 1000 == 0:
                        elapsed = time.time() - start_time
                        rate = received_count / elapsed
                        print(f"[{get_kr_time()}][UDP] ìˆ˜ì‹  í†µê³„: {received_count}ê°œ íŒ¨í‚·, {rate:.2f} packets/sec")
            except Exception as e:
                print(f"[{get_kr_time()}][UDP] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            finally:
                if self.udp_sock:
                    self.udp_sock.close()
                    
        thread = threading.Thread(target=_udp_receiver)
        thread.daemon = True
        thread.start()
        return thread

    def start_tcp_server(self):
        """TCP ì„œë²„ ì´ˆê¸°í™” ë° ì‹œì‘"""
        def _tcp_server():
            try:
                self.tcp_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.tcp_server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                self.tcp_server.bind((AI_SERVICE_IP, SPEAKER_PORT))
                self.tcp_server.listen(1)
                
                print(f"[{get_kr_time()}][TCP] ìŠ¤í”¼ì»¤ ë…¸ë“œ ì—°ê²° ëŒ€ê¸° ì¤‘... (í¬íŠ¸: {SPEAKER_PORT})")
                
                while not self.stop_event.is_set():
                    self.tcp_server.settimeout(1.0)  # 1ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
                    try:
                        self.tcp_client, addr = self.tcp_server.accept()
                        print(f"[{get_kr_time()}][TCP] ìŠ¤í”¼ì»¤ ë…¸ë“œ ì—°ê²°ë¨: {addr}")
                        self.tcp_ready.set()  # TCP ì—°ê²° ì™„ë£Œ ì‹ í˜¸
                        
                        # í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ëŠì–´ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°
                        while not self.stop_event.is_set():
                            time.sleep(1)
                            try:
                                # ì—°ê²° ìƒíƒœ í™•ì¸
                                self.tcp_client.send(b'')
                            except:
                                print(f"[{get_kr_time()}][TCP] í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ëŠì–´ì§")
                                self.tcp_ready.clear()
                                break
                                
                    except socket.timeout:
                        continue
                    except Exception as e:
                        print(f"[{get_kr_time()}][TCP] ì—°ê²° ì˜¤ë¥˜: {str(e)}")
                        self.tcp_ready.clear()
                        time.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        
            except Exception as e:
                print(f"[{get_kr_time()}][TCP] ì„œë²„ ì˜¤ë¥˜: {str(e)}")
            finally:
                if self.tcp_client:
                    self.tcp_client.close()
                if self.tcp_server:
                    self.tcp_server.close()
                    
        thread = threading.Thread(target=_tcp_server)
        thread.daemon = True
        thread.start()
        return thread

    def send_audio_data(self, audio_data):
        """TTS ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ TCPë¡œ ì „ì†¡"""
        if not self.tcp_ready.is_set():
            print(f"[{get_kr_time()}][TCP] âš ï¸ ìŠ¤í”¼ì»¤ ë…¸ë“œê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # ë°ì´í„° í¬ê¸° ì „ì†¡ (4ë°”ì´íŠ¸)
            total_size = len(audio_data) * 4  # float32ëŠ” 4ë°”ì´íŠ¸
            self.tcp_client.send(total_size.to_bytes(4, byteorder='big'))
            
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡
            for i in range(0, len(audio_data), CHUNK):
                chunk = audio_data[i:i + CHUNK]
                if len(chunk) < CHUNK:
                    chunk = np.pad(chunk, (0, CHUNK - len(chunk)))
                self.tcp_client.send(chunk.tobytes())
                
            return True
            
        except Exception as e:
            print(f"[{get_kr_time()}][TCP] ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
            self.tcp_ready.clear()
            return False

    def cleanup(self):
        """ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.stop_event.set()
        if self.tcp_client:
            self.tcp_client.close()
        if self.tcp_server:
            self.tcp_server.close()
        if self.udp_sock:
            self.udp_sock.close()

def init_tcp_server():
    """TCP ì„œë²„ ì´ˆê¸°í™” ë° í´ë¼ì´ì–¸íŠ¸ ëŒ€ê¸°"""
    global tcp_server, tcp_client
    
    # TCP ì„œë²„ ì†Œì¼“ ìƒì„±
    tcp_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server.bind((AI_SERVICE_IP, SPEAKER_PORT))
    tcp_server.listen(1)
    
    print(f"[{get_kr_time()}][TCP] ìŠ¤í”¼ì»¤ ë…¸ë“œ ì—°ê²° ëŒ€ê¸° ì¤‘... (í¬íŠ¸: {SPEAKER_PORT})")
    tcp_client, addr = tcp_server.accept()
    print(f"[{get_kr_time()}][TCP] ìŠ¤í”¼ì»¤ ë…¸ë“œ ì—°ê²°ë¨: {addr}")

def main():
    # ========== 1. í†µì‹  ê´€ë¦¬ì ì´ˆê¸°í™” ==========
    print(f"[{get_kr_time()}][INIT] í†µì‹  ê´€ë¦¬ì ì´ˆê¸°í™” ì¤‘...")
    comm_manager = CommunicationManager()
    
    # UDP ìˆ˜ì‹ ê¸° ë° TCP ì„œë²„ ì‹œì‘ (ë¹„ë™ê¸°)
    udp_thread = comm_manager.start_udp_receiver()
    tcp_thread = comm_manager.start_tcp_server()

    # ========== 2. Porcupine ì›¨ì´í¬ì›Œë“œ ì—”ì§„ ==========
    print(f"[{get_kr_time()}][INIT] Porcupine ì›¨ì´í¬ì›Œë“œ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    porcupine = pvporcupine.create(
        access_key=PICOVOICE_ACCESS_KEY,
        keyword_paths=[PORCUPINE_KEYWORD_PATH],
        model_path=PORCUPINE_MODEL_PATH
    )
    mic_frame_length = int(porcupine.frame_length * (NATIVE_RATE / TARGET_RATE))
    print(f"[{get_kr_time()}][CONFIG] í”„ë ˆì„ ê¸¸ì´: {mic_frame_length}, ì›ë³¸ ë ˆì´íŠ¸: {NATIVE_RATE}Hz, íƒ€ê²Ÿ ë ˆì´íŠ¸: {TARGET_RATE}Hz")
    print(f"[{get_kr_time()}][talker_manager] Ready for wakeword detection: 'ë¦¬ë³´ì•¼'")
    buffer = b''

    # ========== 3. OpenAI í´ë¼ì´ì–¸íŠ¸ ==========
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    recognizer = sr.Recognizer()

    try:
        while True:
            # --- UDPë¡œë¶€í„° ë°ì´í„° ëˆ„ì  ---
            while not comm_manager.buffer_queue.empty():
                buffer += comm_manager.buffer_queue.get()

            # --- mic_frame_length ë‹¨ìœ„ë¡œ ì²˜ë¦¬ ---
            while len(buffer) >= mic_frame_length * 2:  # int16ì€ 2bytes
                frame_bytes = buffer[:mic_frame_length * 2]
                buffer = buffer[mic_frame_length * 2:]

                pcm_native = struct.unpack_from("h" * mic_frame_length, frame_bytes)
                audio_np = np.array(pcm_native, dtype=np.float32)
                audio_resampled = resampy.resample(audio_np, NATIVE_RATE, TARGET_RATE)
                pcm_resampled = audio_resampled.astype(np.int16)

                # ========== 4. ì›¨ì´í¬ì›Œë“œ ê²€ì¶œ ==========
                keyword_index = porcupine.process(pcm_resampled)
                if keyword_index >= 0:
                    print(f"\n[{get_kr_time()}][WAKE] ğŸŸ¢ Wakeword('ë¦¬ë³´ì•¼') ê°ì§€ë¨!")
                    print(f"[{get_kr_time()}][AUDIO] í˜„ì¬ ë²„í¼ í¬ê¸°: {len(buffer)} bytes")
                    
                    # ì›¨ì´í¬ì›Œë“œ ê°ì§€ ì‹œ "ë„¤? ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?" TTS ì¶œë ¥
                    print(f"[{get_kr_time()}][TTS] ì›¨ì´í¬ì›Œë“œ í™•ì¸ ì‘ë‹µ ìƒì„± ì¤‘...")
                    
                    wake_response = "ë„¤? ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
                    synthesis_input = texttospeech.SynthesisInput(text=wake_response)
                    
                    voice = texttospeech.VoiceSelectionParams(
                        language_code="ko-KR",
                        name="ko-KR-Standard-A",
                        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
                    )
                    
                    audio_config = texttospeech.AudioConfig(
                        audio_encoding=texttospeech.AudioEncoding.LINEAR16,
                        sample_rate_hertz=TTS_RATE,
                    )
                    
                    try:
                        wake_tts_response = tts_client.synthesize_speech(
                            input=synthesis_input,
                            voice=voice,
                            audio_config=audio_config
                        )
                        
                        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ float32ë¡œ ë³€í™˜
                        wake_audio_data = np.frombuffer(wake_tts_response.audio_content, dtype=np.int16)
                        wake_audio_float32 = wake_audio_data.astype(np.float32) / 32768.0
                        
                        # TCPë¥¼ í†µí•´ ìŠ¤í”¼ì»¤ ë…¸ë“œë¡œ ì „ì†¡
                        print(f"[{get_kr_time()}][AUDIO] ì›¨ì´í¬ì›Œë“œ ì‘ë‹µ ì „ì†¡ ì¤‘...")
                        
                        if comm_manager.send_audio_data(wake_audio_float32):
                            print(f"[{get_kr_time()}][AUDIO] ì›¨ì´í¬ì›Œë“œ ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")
                        else:
                            print(f"[{get_kr_time()}][AUDIO] âŒ ì›¨ì´í¬ì›Œë“œ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨")
                            
                    except Exception as e:
                        print(f"[{get_kr_time()}][ERROR] ì›¨ì´í¬ì›Œë“œ TTS ì˜¤ë¥˜: {str(e)}")
                    
                    # ì—¬ê¸°ì„œ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ë‹«ê±°ë‚˜ ëª¨ë“œ ì „í™˜ í•„ìš” ì—†ìŒ (ì´ë¯¸ UDP ì…ë ¥ì¤‘)
                    # ì´í›„: ëª…ë ¹ì–´ ì¸ì‹ ë‹¨ê³„
                    # ---- ëª…ë ¹ì–´ ì¸ì‹(êµ¬ê¸€ STT API í™œìš©) ----
                    print(f"[{get_kr_time()}][STT] ë‹¤ìŒ ëª…ë ¹ì„ ë§ì”€í•˜ì„¸ìš”... (ìµœëŒ€ 15ì´ˆ)")

                    # [1] ìŒì„± ìˆ˜ì§‘ ë° ë…¸ì´ì¦ˆ ë ˆë²¨ ì¡°ì • (ì›ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì‚¬ìš©)
                    print(f"[{get_kr_time()}][AUDIO] ì£¼ë³€ ì†ŒìŒ ë¶„ì„ ì¤‘... (0.5ì´ˆ)")
                    print(f"[{get_kr_time()}][CONFIG] ìŒì„± ì¸ì‹ì„ ìœ„í•´ ì›ë³¸ ë ˆì´íŠ¸({NATIVE_RATE}Hz) ì‚¬ìš©")
                    
                    # WAV íŒŒì¼ë¡œ í˜„ì¬ ë²„í¼ì˜ ë°ì´í„° ì €ì¥ (ì„ì‹œ)
                    noise_wav = os.path.join(PROJECT_ROOT, "temp_noise.wav")
                    collected = b''
                    
                    # ë…¸ì´ì¦ˆ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ (0.5ì´ˆ)
                    start = time.time()
                    while time.time() - start < 0.5:  # 0.5ì´ˆ ë™ì•ˆ ë°ì´í„° ìˆ˜ì§‘
                        if not comm_manager.buffer_queue.empty():
                            collected += comm_manager.buffer_queue.get()
                    
                    # WAV íŒŒì¼ë¡œ ì €ì¥ - ì›ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸(NATIVE_RATE) ì‚¬ìš©
                    with wave.open(noise_wav, 'wb') as wf:
                        wf.setnchannels(CHANNELS)
                        wf.setsampwidth(2)  # 16-bit
                        wf.setframerate(NATIVE_RATE)
                        wf.writeframes(collected)
                    
                    # ë…¸ì´ì¦ˆ ë ˆë²¨ ì¡°ì •
                    with sr.AudioFile(noise_wav) as source:
                        recognizer.adjust_for_ambient_noise(source, duration=0.5)
                        print(f"[{get_kr_time()}][AUDIO] ë…¸ì´ì¦ˆ ë ˆë²¨ ì¡°ì • ì™„ë£Œ")
                    
                    os.remove(noise_wav)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    
                    # [2] ì‹¤ì œ ìŒì„± ìˆ˜ì§‘ ì‹œì‘ (ì¹¨ë¬µ ê°ì§€ ê¸°ëŠ¥ ì¶”ê°€)
                    print(f"[{get_kr_time()}][RECORD] ìŒì„± ìˆ˜ì§‘ ì‹œì‘... (ìµœëŒ€ 15ì´ˆ, ì¹¨ë¬µ ê°ì§€ì‹œ ìë™ ì¢…ë£Œ)")
                    collected = b''
                    start = time.time()
                    MAX_RECORD_TIME = 15.0  # ìµœëŒ€ 15ì´ˆ
                    SILENCE_THRESHOLD = 300  # ì¹¨ë¬µ ê°ì§€ ì„ê³„ê°’ (RMS)
                    SILENCE_DURATION = 1.5  # ì¹¨ë¬µì´ ì§€ì†ë˜ì–´ì•¼ í•˜ëŠ” ì‹œê°„(ì´ˆ)
                    
                    last_active_time = time.time()  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì†Œë¦¬ê°€ ê°ì§€ëœ ì‹œê°„
                    has_speech_started = False  # ìŒì„±ì´ ì‹œì‘ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
                    
                    try:
                        while time.time() - start < MAX_RECORD_TIME:
                            if not comm_manager.buffer_queue.empty():
                                data = comm_manager.buffer_queue.get()
                                collected += data
                                
                                # í˜„ì¬ ì²­í¬ì˜ ì†Œë¦¬ í¬ê¸° ì¸¡ì • (RMS)
                                if len(data) >= CHUNK * 2:  # ìµœì†Œ 1ê°œ ì²­í¬ ì´ìƒ
                                    pcm = struct.unpack_from("h" * (len(data) // 2), data)
                                    rms = np.sqrt(np.mean(np.square(pcm)))
                                    
                                    # ì†Œë¦¬ê°€ ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ í™œë™ìœ¼ë¡œ ê°„ì£¼
                                    if rms > SILENCE_THRESHOLD:
                                        last_active_time = time.time()
                                        if not has_speech_started and len(collected) > CHUNK * 10:  # ì²˜ìŒ ëª‡ ì²­í¬ëŠ” ë…¸ì´ì¦ˆì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê±´ë„ˆëœ€
                                            has_speech_started = True
                                            print(f"[{get_kr_time()}][RECORD] ğŸ—£ï¸ ìŒì„± ê°ì§€ë¨ (RMS: {rms:.1f})")
                                
                                # ë¡œê·¸ ì¶œë ¥
                                if len(collected) % (CHUNK * 10) == 0:
                                    elapsed = time.time() - start
                                    print(f"[{get_kr_time()}][RECORD] ìˆ˜ì§‘ëœ ë°ì´í„°: {len(collected)} bytes (ê²½ê³¼ ì‹œê°„: {elapsed:.1f}ì´ˆ)")
                                
                                # ì¹¨ë¬µ ê°ì§€ ë¡œì§: ìŒì„±ì´ ì‹œì‘ëœ í›„ ì¼ì • ì‹œê°„ë™ì•ˆ ì¹¨ë¬µì´ ê³„ì†ë˜ë©´ ë…¹ìŒ ì¢…ë£Œ
                                if has_speech_started and time.time() - last_active_time > SILENCE_DURATION:
                                    print(f"[{get_kr_time()}][RECORD] â¹ï¸ ì¹¨ë¬µ ê°ì§€: {SILENCE_DURATION}ì´ˆ ë™ì•ˆ ì†Œë¦¬ê°€ ì—†ì–´ ë…¹ìŒ ì¢…ë£Œ")
                                    break
                                    
                            else:
                                time.sleep(0.01)
                    except Exception as e:
                        print(f"[{get_kr_time()}][ERROR] ìŒì„± ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    
                    duration = time.time() - start
                    print(f"[{get_kr_time()}][RECORD] ìŒì„± ìˆ˜ì§‘ ì™„ë£Œ. ì´ {len(collected)} bytes, ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")

                    # [2] WAVíŒŒì¼ë¡œ ì €ì¥ â†’ SpeechRecognitionì—ì„œ ë¡œë“œ
                    tmp_wav = os.path.join(PROJECT_ROOT, "temp_cmd.wav")
                    wf = wave.open(tmp_wav, 'wb')
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(2)
                    wf.setframerate(NATIVE_RATE)
                    wf.writeframes(collected)
                    wf.close()

                    with sr.AudioFile(tmp_wav) as source:
                        print(f"[{get_kr_time()}][STT] ìŒì„± íŒŒì¼ ë¡œë“œ ì™„ë£Œ. êµ¬ê¸€ STT API í˜¸ì¶œ ì¤‘...")
                        audio = recognizer.record(source)
                        try:
                            transcript = recognizer.recognize_google(audio, language="ko-KR")
                            print(f"[{get_kr_time()}][STT] ì‚¬ìš©ì ë°œí™”: {transcript}")
                        except sr.UnknownValueError:
                            transcript = None
                            print(f"[{get_kr_time()}][STT] âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨ (ìŒì„±ì„ ê°ì§€í•  ìˆ˜ ì—†ìŒ)")
                        except Exception as e:
                            transcript = None
                            print(f"[{get_kr_time()}][STT] âŒ STT ì˜¤ë¥˜: {e}")

                    os.remove(tmp_wav)

                    # [3] OpenAIë¡œ ì˜ë„ ë¶„ì„
                    if transcript:
                        system_prompt = (
                            "ë‹¹ì‹ ì€ ë¡œë´‡ì˜ ìŒì„± ëª…ë ¹ì„ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤.\n"
                            "ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ë“£ê³ , ì•„ë˜ 4ê°€ì§€ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n\n"
                            "- pause_navigation: 'ì ê¹ ë©ˆì¶°', 'ë©ˆì¶°ë´' ë“± ì¼ì‹œì •ì§€ ëª…ë ¹\n"
                            "- resume_follow: 'ë‹¤ì‹œ ë”°ë¼ì™€', 'ë‹¤ì‹œ ì‹œì‘í•´' ë“± íŒ”ë¡œìœ™ ì¬ê°œ ëª…ë ¹\n"
                            "- end_follow: 'ê·¸ë§Œ ë”°ë¼ì™€', 'íŒ”ë¡œìœ™ ì¢…ë£Œ' ë“± íŒ”ë¡œìœ™ ì¢…ë£Œ ëª…ë ¹\n"
                            "- ignore: 'ê³ ë§ˆì›Œ', 'ì•„ë‹ˆì•¼' ë“± ê¸°íƒ€ ëŒ€í™”ë‚˜ ë¬´ì‹œí•´ë„ ë˜ëŠ” í‘œí˜„\n\n"
                            "ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤:\n"
                            '{"intent": "..."}'
                        )
                        completion = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": transcript}
                            ]
                        )
                        ai_text = completion.choices[0].message.content
                        print(f"[{get_kr_time()}][GPT] AI ì‘ë‹µ: {ai_text}")
                        import re
                        match = re.search(r'{"intent":\s*"(\w+)"}', ai_text)
                        if match:
                            intent = match.group(1)
                            print(f"[{get_kr_time()}][INTENT] ê°ì§€ëœ ì˜ë„: {intent}")
                        else:
                            intent = "ignore"
                            print(f"[{get_kr_time()}][INTENT] âš ï¸ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ 'ignore' ì‚¬ìš©")

                        intent_responses = {
                            "pause_navigation": "ë„¤, ì¼ì‹œì •ì§€ í•˜ê² ìŠµë‹ˆë‹¤.",
                            "resume_follow": "ë„¤, íŒ”ë¡œìœ™ì„ ë‹¤ì‹œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
                            "end_follow": "ë„¤, íŒ”ë¡œìœ™ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
                            "ignore": "ë“±ë¡ë˜ì§€ ì•Šì€ ëª…ë ¹ì…ë‹ˆë‹¤. ë¬´ì‹œí•˜ê² ìŠµë‹ˆë‹¤."
                        }
                        response = intent_responses.get(intent, "ë“±ë¡ë˜ì§€ ì•Šì€ ëª…ë ¹ì…ë‹ˆë‹¤.")
                        print(f"[{get_kr_time()}][RESPONSE] {response}")
                        
                        # TTSë¡œ ì‘ë‹µ ìƒì„±
                        print(f"[{get_kr_time()}][TTS] ìŒì„± ì‘ë‹µ ìƒì„± ì¤‘...")
                        synthesis_input = texttospeech.SynthesisInput(text=response)
                        
                        voice = texttospeech.VoiceSelectionParams(
                            language_code="ko-KR",
                            name="ko-KR-Standard-A",
                            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
                        )
                        
                        audio_config = texttospeech.AudioConfig(
                            audio_encoding=texttospeech.AudioEncoding.LINEAR16,
                            sample_rate_hertz=TTS_RATE,
                        )
                        
                        try:
                            tts_response = tts_client.synthesize_speech(
                                input=synthesis_input,
                                voice=voice,
                                audio_config=audio_config
                            )
                            
                            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ float32ë¡œ ë³€í™˜
                            audio_data = np.frombuffer(tts_response.audio_content, dtype=np.int16)
                            audio_float32 = audio_data.astype(np.float32) / 32768.0
                            
                            # TCPë¥¼ í†µí•´ ìŠ¤í”¼ì»¤ ë…¸ë“œë¡œ ì „ì†¡
                            print(f"[{get_kr_time()}][AUDIO] ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ì¤‘...")
                            
                            if comm_manager.send_audio_data(audio_float32):
                                print(f"[{get_kr_time()}][AUDIO] ì „ì†¡ ì™„ë£Œ")
                            else:
                                print(f"[{get_kr_time()}][AUDIO] âŒ ì „ì†¡ ì‹¤íŒ¨")
                            
                        except Exception as e:
                            print(f"[{get_kr_time()}][ERROR] TTS/ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
                            
                    print(f"[{get_kr_time()}][SYSTEM] 'ë¦¬ë³´ì•¼' ì´í›„ ëª…ë ¹ ì²˜ë¦¬ ì™„ë£Œ, ë‹¤ì‹œ ì›¨ì´í¬ì›Œë“œ ëŒ€ê¸° ì¤‘...")

            time.sleep(0.01)
    except KeyboardInterrupt:
        print("[talker_manager] ì¢…ë£Œ ìš”ì²­ë¨.")
    finally:
        print(f"[{get_kr_time()}][CLEANUP] í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì¤‘...")
        comm_manager.cleanup()
        udp_thread.join()
        tcp_thread.join()
        if 'porcupine' in locals():
            porcupine.delete()
        print(f"[{get_kr_time()}][SYSTEM] í”„ë¡œê·¸ë¨ì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    main()
