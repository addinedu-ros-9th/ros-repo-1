# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
import cv2
import torch
import time
import socket
import json
import numpy as np
from pathlib import Path
from strongsort.strong_sort import StrongSORT
import threading

# ===== ì„¤ì •: ëª¨ë¸, í†µì‹ , ì¶”ì  íŒŒë¼ë¯¸í„° ì •ì˜ =====
# --- ëª¨ë¸ ì„¤ì • ---
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
YOLO_MODEL_NAME = 'yolov5m'
REID_WEIGHT_PATH = Path('./osnet_x1_0_msmt17.pt') # ì‹¤ì œ Re-ID ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.

# --- í†µì‹  ì„¤ì • ---
# 1. ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ì„ ìˆ˜ì‹ í•  í¬íŠ¸ (cam_senderê°€ ë³´ë‚´ëŠ” ê³³)
IMAGE_LISTEN_PORT = 7003
# 2. ROS2 ë…¸ë“œë¡œ ì¶”ì  ìƒíƒœë¥¼ ì „ì†¡í•  ì£¼ì†Œ
ROS_BRIDGE_IP = '127.0.0.1'
ROS_BRIDGE_PORT = 7008
# 3. ROS2 ë…¸ë“œë¡œë¶€í„° ëª…ë ¹ì„ ìˆ˜ì‹ í•  í¬íŠ¸
CMD_LISTEN_PORT = 7009

# --- ì¶”ì  íŒŒë¼ë¯¸í„° ---
REID_THRESHOLD = 0.4
FEATURE_UPDATE_ALPHA = 0.1

# ===== ëª¨ë¸ ë¡œë“œ: YOLOv5ì™€ StrongSORT ì´ˆê¸°í™” =====
print("ğŸ¤– ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤...")
yolo_model = torch.hub.load('ultralytics/yolov5', YOLO_MODEL_NAME, pretrained=True).to(DEVICE)
tracker = StrongSORT(
    model_weights=REID_WEIGHT_PATH, device=DEVICE, fp16=False,
    max_age=200, max_dist=0.3, max_iou_distance=0.7, n_init=3
)
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# ===== ì†Œì¼“ ì„¤ì •: 3ê°œì˜ í†µì‹  ì±„ë„ì„ ìœ„í•œ ì†Œì¼“ ìƒì„± =====
# 1. ì´ë¯¸ì§€ ìˆ˜ì‹ ìš© ì†Œì¼“
image_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
image_sock.bind(('0.0.0.0', IMAGE_LISTEN_PORT))

# 2. ìƒíƒœ ì „ì†¡ìš© ì†Œì¼“
status_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

# 3. ëª…ë ¹ ìˆ˜ì‹ ìš© ì†Œì¼“
cmd_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
cmd_sock.bind(('0.0.0.0', CMD_LISTEN_PORT))

# ===== ìƒíƒœ ë³€ìˆ˜: ìŠ¤ë ˆë“œ ê°„ ê³µìœ  ë°ì´í„° =====
target_id = None
target_lost_time = None
target_mean_feature = None
state_lock = threading.Lock() # ìŠ¤ë ˆë“œ ë™ê¸°í™”ë¥¼ ìœ„í•œ Lock

def command_listener():
    """ROS2 ë…¸ë“œë¡œë¶€í„° ì˜¤ëŠ” ëª…ë ¹(íƒ€ê²Ÿ ì§€ì •/í•´ì œ)ì„ ìˆ˜ì‹ í•˜ëŠ” ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
    global target_id, target_mean_feature, target_lost_time
    print(f"ğŸ‘‚ ROS2 ëª…ë ¹ ìˆ˜ì‹  ëŒ€ê¸° ì‹œì‘ (í¬íŠ¸: {CMD_LISTEN_PORT})")
    while True:
        try:
            data, _ = cmd_sock.recvfrom(1024)
            command = json.loads(data.decode())
            
            with state_lock:
                if command.get('command') == 'set_target':
                    new_target_id = command.get('target_id')
                    if new_target_id is not None:
                        print(f"ğŸ¯ ëª…ë ¹ ìˆ˜ì‹ : íƒ€ê²Ÿì„ ID {new_target_id}(ìœ¼)ë¡œ ì„¤ì •")
                        target_id, target_mean_feature, target_lost_time = new_target_id, None, None
                elif command.get('command') == 'clear_target':
                    print("ğŸ—‘ï¸ ëª…ë ¹ ìˆ˜ì‹ : íƒ€ê²Ÿ í•´ì œ")
                    target_id, target_mean_feature, target_lost_time = None, None, None
        except Exception as e:
            print(f"â— ëª…ë ¹ ìˆ˜ì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ëª…ë ¹ ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì‹œì‘
threading.Thread(target=command_listener, daemon=True).start()

print(f"ğŸš€ ì¶”ì  ì‹œìŠ¤í…œ ì‹œì‘. UDP í¬íŠ¸ {IMAGE_LISTEN_PORT}ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

try:
    while True:
        # ===== 1. ì´ë¯¸ì§€ ìˆ˜ì‹  ë° ë””ì½”ë”© =====
        # UDP íŒ¨í‚· ìˆ˜ì‹  (ë²„í¼ í¬ê¸°ë¥¼ ë„‰ë„‰í•˜ê²Œ ì„¤ì •)
        data, _ = image_sock.recvfrom(65536)

        # 'í—¤ë” | ì´ë¯¸ì§€' í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë¶„ë¦¬
        separator_pos = data.find(b'|')
        if separator_pos == -1:
            print("âš ï¸ ìˆ˜ì‹ ëœ íŒ¨í‚· í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (êµ¬ë¶„ì '|' ì—†ìŒ)")
            continue
        
        # í—¤ë”ì™€ JPEG ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë¶„ë¦¬
        # header_bytes = data[:separator_pos] # í—¤ë” ì •ë³´ëŠ” í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        jpeg_bytes = data[separator_pos+1:]

        # JPEG ë°”ì´íŠ¸ë¥¼ OpenCVê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€(Numpy ë°°ì—´)ë¡œ ë””ì½”ë”©
        np_arr = np.frombuffer(jpeg_bytes, np.uint8)
        frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        if frame is None:
            print("âš ï¸ JPEG ì´ë¯¸ì§€ ë””ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            continue

        # ===== 2. ê°ì²´ íƒì§€ ë° ì¶”ì  (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼) =====
        results = yolo_model(frame)
        detections = results.xyxy[0]
        person_detections = detections[detections[:, 5] == 0]

        tracked_outputs = tracker.update(person_detections.cpu(), frame) if len(person_detections) > 0 else []
        if len(person_detections) == 0:
            tracker.increment_ages()

        current_tracks = {t.track_id: t for t in tracker.tracker.tracks}
        found_target = False
        lost_time = 0

        with state_lock:
            if target_id is not None and target_id in current_tracks:
                found_target = True
                target_lost_time = None
                current_feature = current_tracks[target_id].features[-1]
                if target_mean_feature is None:
                    target_mean_feature = current_feature
                else:
                    target_mean_feature = (1 - FEATURE_UPDATE_ALPHA) * target_mean_feature + FEATURE_UPDATE_ALPHA * current_feature
                    target_mean_feature /= np.linalg.norm(target_mean_feature)
            
            if not found_target and target_id is not None:
                if target_lost_time is None: target_lost_time = time.time()
                lost_time = time.time() - target_lost_time

                if target_mean_feature is not None and len(current_tracks) > 0:
                    best_match_id, min_dist = -1, float('inf')
                    for track_id, track in current_tracks.items():
                        if track.is_confirmed() and track.features:
                            dist = 1 - np.dot(track.features[-1], target_mean_feature)
                            if dist < min_dist: min_dist, best_match_id = dist, track_id
                    
                    if min_dist < REID_THRESHOLD:
                        print(f"ğŸ”„ íƒ€ê²Ÿ ì¬ì‹ë³„ ì„±ê³µ! ID {target_id} -> {best_match_id} (ê±°ë¦¬: {min_dist:.3f})")
                        target_id, target_lost_time, lost_time = best_match_id, None, 0
        
        # ===== 3. ìƒíƒœ ì „ì†¡ ë° ì‹œê°í™” (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼) =====
        message = {'timestamp': time.time(), 'lost_time': lost_time}
        status_sock.sendto(json.dumps(message).encode(), (ROS_BRIDGE_IP, ROS_BRIDGE_PORT))

        for output in tracked_outputs:
            x1, y1, x2, y2, track_id_out = map(int, output[:5])
            color, label = ((255, 0, 0), f"ID {track_id_out}")
            if track_id_out == target_id:
                color, label = ((0, 255, 0), f"TARGET: {track_id_out}")
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        if lost_time > 0:
            cv2.putText(frame, f"TARGET LOST: {lost_time:.1f}s", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        cv2.imshow("Object Tracker (UDP Input)", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("\n[ì¢…ë£Œ] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
finally:
    print("ì†Œì¼“ì„ ë‹«ê³  í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    image_sock.close()
    status_sock.close()
    cmd_sock.close()
    cv2.destroyAllWindows()