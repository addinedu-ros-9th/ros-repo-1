# object_tracker.py

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import cv2  # OpenCV: ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch  # PyTorch: ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬
import time  # ì‹œê°„ ê´€ë ¨ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import socket  # UDP í†µì‹ ì„ ìœ„í•œ ì†Œì¼“ ë¼ì´ë¸ŒëŸ¬ë¦¬
import json  # JSON í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚°, íŠ¹íˆ í–‰ë ¬ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pathlib import Path  # íŒŒì¼ ê²½ë¡œë¥¼ ê°ì²´ ì§€í–¥ì ìœ¼ë¡œ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from strongsort.strong_sort import StrongSORT  # ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ StrongSORT ì„í¬íŠ¸
import threading  # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ë ˆë”© ë¼ì´ë¸ŒëŸ¬ë¦¬
import math  # ìˆ˜í•™ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ===== ì„¤ì • (Configuration) =====
# ì´ ìŠ¤í¬ë¦½íŠ¸ì˜ ë™ì‘ì„ ì œì–´í•˜ëŠ” ì£¼ìš” ë³€ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.

# ë”¥ëŸ¬ë‹ ì—°ì‚°ì„ ìˆ˜í–‰í•  ì¥ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. NVIDIA GPU(cuda)ê°€ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
# ì‚¬ìš©í•  YOLO(You Only Look Once) ê°ì²´ íƒì§€ ëª¨ë¸ì˜ ë²„ì „ì„ ì§€ì •í•©ë‹ˆë‹¤. 'm'ì€ medium ëª¨ë¸ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
YOLO_MODEL_NAME = 'yolov5m'
# ì¬ì‹ë³„(Re-identification) ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤. StrongSORTê°€ ê°ì²´ì˜ ì™¸ëª¨ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©í•©ë‹ˆë‹¤.
REID_WEIGHT_PATH = Path('./osnet_x1_0_msmt17.pt')
# ì´ë¯¸ì§€(ë¹„ë””ì˜¤ í”„ë ˆì„)ë¥¼ ìˆ˜ì‹ í•  UDP í¬íŠ¸ ë²ˆí˜¸ì…ë‹ˆë‹¤.
IMAGE_LISTEN_PORT = 7003
# ì¶”ì  ìƒíƒœ ì •ë³´ë¥¼ ì „ì†¡í•  ROS ë¸Œë¦¿ì§€ì˜ IP ì£¼ì†Œì…ë‹ˆë‹¤. (ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” 127.0.0.1)
ROS_BRIDGE_IP = '127.0.0.1'
# ì¶”ì  ìƒíƒœ ì •ë³´ë¥¼ ì „ì†¡í•  ROS ë¸Œë¦¿ì§€ì˜ í¬íŠ¸ ë²ˆí˜¸ì…ë‹ˆë‹¤.
ROS_BRIDGE_PORT = 7008
# ì™¸ë¶€(ROS)ë¡œë¶€í„° ì œì–´ ëª…ë ¹ì„ ìˆ˜ì‹ í•  UDP í¬íŠ¸ ë²ˆí˜¸ì…ë‹ˆë‹¤.
CMD_LISTEN_PORT = 7009
# ì¬ì‹ë³„ ì‹œ, ë‘ ê°ì²´ì˜ ì™¸ëª¨ íŠ¹ì§• ë²¡í„° ê°„ì˜ ê±°ë¦¬ê°€ ì´ ê°’ë³´ë‹¤ ì‘ì•„ì•¼ ë™ì¼ ê°ì²´ë¡œ íŒë‹¨í•©ë‹ˆë‹¤. ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ì—„ê²©í•©ë‹ˆë‹¤.
REID_THRESHOLD = 0.4
# ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì˜ ì™¸ëª¨ íŠ¹ì§•ì„ ê°±ì‹ í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í•™ìŠµë¥ ì…ë‹ˆë‹¤. ì¡°ëª…ì´ë‚˜ ìì„¸ ë³€í™”ì— ì ì§„ì ìœ¼ë¡œ ì ì‘í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.
FEATURE_UPDATE_ALPHA = 0.1
last_status_send_time = 0  # ë£¨í”„ ë°–ì— ì •ì˜

# ===== ëª¨ë¸ ë¡œë“œ (Model Loading) =====
print("ğŸ¤– ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤...")
# YOLOv5 ëª¨ë¸ì„ PyTorch Hubë¥¼ í†µí•´ ë¡œë“œí•˜ê³ , ì§€ì •ëœ ì¥ì¹˜(DEVICE)ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
yolo_model = torch.hub.load('ultralytics/yolov5', YOLO_MODEL_NAME, pretrained=True).to(DEVICE)
# StrongSORT ì¶”ì ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
tracker = StrongSORT(
    model_weights=REID_WEIGHT_PATH,  # ì¬ì‹ë³„ ëª¨ë¸ ê°€ì¤‘ì¹˜
    device=DEVICE,  # ì—°ì‚° ì¥ì¹˜
    fp16=False,  # ë°˜ì •ë°€ë„(16ë¹„íŠ¸) ë¶€ë™ì†Œìˆ˜ì  ì—°ì‚° ì‚¬ìš© ì—¬ë¶€
    max_age=200,  # ê°ì²´ê°€ í™”ë©´ì—ì„œ ì‚¬ë¼ì§„ í›„ ìµœëŒ€ ëª‡ í”„ë ˆì„ê¹Œì§€ ì •ë³´ë¥¼ ìœ ì§€í• ì§€ ê²°ì • (íƒ€ì´ë¨¸ ë¬¸ì œì˜ í•µì‹¬)
    max_dist=0.3,  # ì™¸ëª¨ íŠ¹ì§•(Re-ID) ê¸°ë°˜ ë§¤ì¹­ ì‹œ ìµœëŒ€ í—ˆìš© ê±°ë¦¬
    max_iou_distance=0.7,  # IoU(Intersection over Union) ê¸°ë°˜ ë§¤ì¹­ ì‹œ ìµœëŒ€ í—ˆìš© ê±°ë¦¬
    n_init=3  # ìƒˆë¡œìš´ íŠ¸ë™ì´ 'í™•ì •(confirmed)' ìƒíƒœê°€ ë˜ê¸° ìœ„í•´ í•„ìš”í•œ ìµœì†Œ í”„ë ˆì„ ìˆ˜
)
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# ===== ì†Œì¼“ ì„¤ì • (Socket Setup) =====
# UDP ì†Œì¼“ì„ ìƒì„±í•©ë‹ˆë‹¤. UDPëŠ” ì‹¤ì‹œê°„ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°ì²˜ëŸ¼ ì•½ê°„ì˜ ë°ì´í„° ì†ì‹¤ì´ ìˆì–´ë„ ë¹ ë¥¸ ì „ì†¡ì´ ì¤‘ìš”í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.
image_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # ì´ë¯¸ì§€ ìˆ˜ì‹ ìš© ì†Œì¼“
image_sock.bind(('0.0.0.0', IMAGE_LISTEN_PORT))  # ëª¨ë“  IP ì£¼ì†Œë¡œë¶€í„°ì˜ ì´ë¯¸ì§€ ìˆ˜ì‹ ì„ í—ˆìš©
status_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # ìƒíƒœ ì „ì†¡ìš© ì†Œì¼“
cmd_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # ëª…ë ¹ ìˆ˜ì‹ ìš© ì†Œì¼“
cmd_sock.bind(('0.0.0.0', CMD_LISTEN_PORT))  # ëª¨ë“  IP ì£¼ì†Œë¡œë¶€í„°ì˜ ëª…ë ¹ ìˆ˜ì‹ ì„ í—ˆìš©

# ===== ìƒíƒœ ë³€ìˆ˜ (State Variables) =====
# ìŠ¤í¬ë¦½íŠ¸ ì „ì—­ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìƒíƒœ ì •ë³´ë“¤ì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.
target_id = None  # í˜„ì¬ ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì˜ ê³ ìœ  ID
target_lost_time = None  # íƒ€ê²Ÿì„ ì²˜ìŒ ë†“ì¹œ ì‹œì ì˜ íƒ€ì„ìŠ¤íƒ¬í”„
target_mean_feature = None  # ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì˜ í‰ê· ì ì¸ ì™¸ëª¨ íŠ¹ì§• ë²¡í„° (ì¬ì‹ë³„ì„ ìœ„í•œ 'ê¸°ì–µ')
find_center_target_flag = False  # 'ì¤‘ì•™ íƒ€ê²Ÿ ì°¾ê¸°' ëª…ë ¹ì´ ìˆ˜ì‹ ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸
state_lock = threading.Lock()  # ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ìƒíƒœ ë³€ìˆ˜ë“¤ì„ ë™ì‹œì— ìˆ˜ì •í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ì ê¸ˆ ì¥ì¹˜ (ë§¤ìš° ì¤‘ìš”)


def command_listener():
    """ROS2 ë…¸ë“œë¡œë¶€í„° ëª…ë ¹ì„ ìˆ˜ì‹ í•˜ëŠ” ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë  í•¨ìˆ˜"""
    global target_id, target_mean_feature, target_lost_time, find_center_target_flag
    print(f"ğŸ‘‚ ROS2 ëª…ë ¹ ìˆ˜ì‹  ëŒ€ê¸° ì‹œì‘ (í¬íŠ¸: {CMD_LISTEN_PORT})")
    while True:  # ë¬´í•œ ë£¨í”„ë¥¼ ëŒë©° ê³„ì†í•´ì„œ ëª…ë ¹ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        try:
            # ì†Œì¼“ì„ í†µí•´ ìµœëŒ€ 1024ë°”ì´íŠ¸ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤.
            data, _ = cmd_sock.recvfrom(1024)
            # ìˆ˜ì‹ ëœ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
            command = json.loads(data.decode())
            
            # state_lockì„ ì‚¬ìš©í•˜ì—¬ ë©”ì¸ ìŠ¤ë ˆë“œì™€ì˜ ì¶©ëŒì„ ë°©ì§€í•˜ë©° ìƒíƒœ ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
            with state_lock:
                if command.get('command') == 'activate_and_find_center':
                    print("ğŸ¯ ëª…ë ¹ ìˆ˜ì‹ : ì¤‘ì•™ íƒ€ê²Ÿ ì°¾ê¸° í™œì„±í™”")
                    # ê¸°ì¡´ íƒ€ê²Ÿ ì •ë³´ë¥¼ ëª¨ë‘ ì´ˆê¸°í™”í•˜ê³ , íƒ€ê²Ÿ ì°¾ê¸° í”Œë˜ê·¸ë¥¼ Trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
                    target_id, target_mean_feature, target_lost_time = None, None, None
                    find_center_target_flag = True 
                elif command.get('command') == 'clear_target':
                    print("ğŸ—‘ï¸ ëª…ë ¹ ìˆ˜ì‹ : íƒ€ê²Ÿ í•´ì œ")
                    # ëª¨ë“  íƒ€ê²Ÿ ì •ë³´ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ì¶”ì ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.
                    target_id, target_mean_feature, target_lost_time = None, None, None
                    find_center_target_flag = False
        except Exception as e:
            print(f"â— ëª…ë ¹ ìˆ˜ì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# command_listener í•¨ìˆ˜ë¥¼ ë°ëª¬ ìŠ¤ë ˆë“œë¡œ ìƒì„±í•˜ê³  ì‹œì‘í•©ë‹ˆë‹¤.
# ë°ëª¬ ìŠ¤ë ˆë“œëŠ” ë©”ì¸ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë  ë•Œ í•¨ê»˜ ì¢…ë£Œë©ë‹ˆë‹¤.
threading.Thread(target=command_listener, daemon=True).start()

print(f"ğŸš€ ì¶”ì  ì‹œìŠ¤í…œ ì‹œì‘. UDP í¬íŠ¸ {IMAGE_LISTEN_PORT}ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

try:
    # ë©”ì¸ ë£¨í”„: í”„ë¡œê·¸ë¨ì˜ í•µì‹¬ ë¡œì§ì„ ë¬´í•œ ë°˜ë³µí•©ë‹ˆë‹¤.
    while True:
        # 1. ì´ë¯¸ì§€ ìˆ˜ì‹  ë° ë””ì½”ë”©
        data, _ = image_sock.recvfrom(65536)  # UDP ë²„í¼ í¬ê¸°ë¥¼ í¬ê²Œ ì¡ì•„ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤.
        separator_pos = data.find(b'|')  # ì»¤ìŠ¤í…€ í”„ë¡œí† ì½œì˜ êµ¬ë¶„ìë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        if separator_pos == -1: continue  # êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ ë°ì´í„°ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.
        jpeg_bytes = data[separator_pos+1:]  # êµ¬ë¶„ì ì´í›„ì˜ ìˆœìˆ˜ JPEG ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        np_arr = np.frombuffer(jpeg_bytes, np.uint8)  # JPEG ë°”ì´íŠ¸ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)  # NumPy ë°°ì—´ì„ OpenCV ì´ë¯¸ì§€ í”„ë ˆì„ìœ¼ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤.
        if frame is None: continue  # ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë£¨í”„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.

        # 2. ê°ì²´ íƒì§€ ë° ì¶”ì 
        results = yolo_model(frame)  # YOLO ëª¨ë¸ë¡œ í˜„ì¬ í”„ë ˆì„ì˜ ëª¨ë“  ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
        detections = results.xyxy[0]  # íƒì§€ ê²°ê³¼ë¥¼ [x1, y1, x2, y2, conf, class] í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        person_detections = detections[detections[:, 5] == 0]  # í´ë˜ìŠ¤ IDê°€ 0ì¸ 'ì‚¬ëŒ'ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        # í•„í„°ë§ëœ ì‚¬ëŒ ì •ë³´ë¥¼ StrongSORT ì¶”ì ê¸°ì— ì „ë‹¬í•˜ì—¬ IDê°€ í¬í•¨ëœ ì¶”ì  ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        tracked_outputs = tracker.update(person_detections.cpu(), frame) if len(person_detections) > 0 else []
        if len(person_detections) == 0: tracker.increment_ages()  # íƒì§€ëœ ì‚¬ëŒì´ ì—†ìœ¼ë©´ ëª¨ë“  íŠ¸ë™ì˜ 'ë‚˜ì´'ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.

        # 3. ìƒíƒœ ê´€ë¦¬ ë° ì¶”ì  ë¡œì§
        current_tracks = {t.track_id: t for t in tracker.tracker.tracks}  # ì¶”ì ê¸°ê°€ 'ê¸°ì–µ'í•˜ëŠ” ëª¨ë“  íŠ¸ë™ ì •ë³´
        current_frame_track_ids = {int(output[4]) for output in tracked_outputs}  # í˜„ì¬ í”„ë ˆì„ì— 'ë³´ì´ëŠ”' íŠ¸ë™ë“¤ì˜ ID ì§‘í•©
        lost_time = 0.0  # í˜„ì¬ í”„ë ˆì„ì—ì„œì˜ ë¶„ì‹¤ ì‹œê°„ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        with state_lock:  # ìŠ¤ë ˆë“œ ì•ˆì „ êµ¬ì—­ ì‹œì‘
            # 3.1. ì¤‘ì•™ íƒ€ê²Ÿ ì°¾ê¸° ëª…ë ¹ ì²˜ë¦¬
            if find_center_target_flag and len(tracked_outputs) > 0:
                frame_center_x, frame_center_y = frame.shape[1] // 2, frame.shape[0] // 2
                min_dist, center_target_id = float('inf'), None
                # í˜„ì¬ ë³´ì´ëŠ” ëª¨ë“  ê°ì²´ì— ëŒ€í•´ í™”ë©´ ì¤‘ì•™ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
                for output in tracked_outputs:
                    x1, y1, x2, y2, track_id_out = map(int, output[:5])
                    box_center_x, box_center_y = (x1 + x2) / 2, (y1 + y2) / 2
                    dist = math.sqrt((box_center_x - frame_center_x)**2 + (box_center_y - frame_center_y)**2)
                    if dist < min_dist:
                        min_dist, center_target_id = dist, track_id_out
                
                # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ë¥¼ ìƒˆë¡œìš´ íƒ€ê²Ÿìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
                if center_target_id is not None:
                    target_id = center_target_id
                    target_lost_time = None  # ìƒˆ íƒ€ê²Ÿì´ë¯€ë¡œ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
                    target_mean_feature = None  # ìƒˆ íƒ€ê²Ÿì´ë¯€ë¡œ ì™¸ëª¨ íŠ¹ì§• ì´ˆê¸°í™”
                    print(f"âœ… ì¤‘ì•™ íƒ€ê²Ÿ ê²°ì •: ID {target_id}")
                
                find_center_target_flag = False  # ëª…ë ¹ì„ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ í”Œë˜ê·¸ë¥¼ ë‹¤ì‹œ Falseë¡œ ì„¤ì •

            # 3.2. íƒ€ê²Ÿ ì¶”ì  ìƒíƒœ ë¨¸ì‹  (State Machine)
            is_target_defined = target_id is not None  # íƒ€ê²Ÿì´ ì§€ì •ë˜ì–´ ìˆëŠ”ê°€?
            is_target_in_frame = is_target_defined and target_id in current_frame_track_ids  # íƒ€ê²Ÿì´ í˜„ì¬ í”„ë ˆì„ì— ë³´ì´ëŠ”ê°€?

            if is_target_in_frame:
                # [ìƒíƒœ: ë°œê²¬] - íƒ€ê²Ÿì´ í˜„ì¬ í”„ë ˆì„ì— ë³´ì´ëŠ” ê²½ìš°
                target_lost_time = None  # ë¶„ì‹¤ íƒ€ì´ë¨¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
                if target_id in current_tracks:
                    current_feature = current_tracks[target_id].features[-1]
                    # íƒ€ê²Ÿì˜ ì™¸ëª¨ íŠ¹ì§•ì„ ë¶€ë“œëŸ½ê²Œ ê°±ì‹ í•˜ì—¬ ë³€í™”ì— ì ì‘í•©ë‹ˆë‹¤.
                    if target_mean_feature is None:
                        target_mean_feature = current_feature
                    else:
                        target_mean_feature = (1 - FEATURE_UPDATE_ALPHA) * target_mean_feature + FEATURE_UPDATE_ALPHA * current_feature
                        target_mean_feature /= np.linalg.norm(target_mean_feature)
            
            elif is_target_defined and not is_target_in_frame:
                # [ìƒíƒœ: ë¶„ì‹¤] - íƒ€ê²Ÿì´ ì§€ì •ì€ ë˜ì–´ìˆì§€ë§Œ í˜„ì¬ í”„ë ˆì„ì— ë³´ì´ì§€ ì•ŠëŠ” ê²½ìš°
                if target_lost_time is None:
                    target_lost_time = time.time()  # 'ë°©ê¸ˆ' ì‚¬ë¼ì¡Œë‹¤ë©´, í˜„ì¬ ì‹œê°„ì„ ë¶„ì‹¤ ì‹œì‘ ì‹œì ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.

                # [ìˆ˜ì •ëœ ì¬ì¸ì‹ ë¡œì§]
                re_id_succeeded = False
                # í˜„ì¬ 'ë³´ì´ëŠ”' ë‹¤ë¥¸ ì‚¬ëŒì´ ìˆê³ , ê¸°ì–µí•˜ëŠ” íƒ€ê²Ÿì˜ ì™¸ëª¨ íŠ¹ì§•ì´ ìˆì„ ë•Œë§Œ ì¬ì¸ì‹ì„ ì‹œë„í•©ë‹ˆë‹¤.
                if target_mean_feature is not None and len(current_frame_track_ids) > 0:
                    best_match_id, min_dist = -1, float('inf')
                    # 'ìœ ë ¹' íŠ¸ë™ì´ ì•„ë‹Œ 'í˜„ì¬ ë³´ì´ëŠ”' íŠ¸ë™ë“¤ ì¤‘ì—ì„œë§Œ ì¬ì¸ì‹ í›„ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                    for visible_id in current_frame_track_ids:
                        if visible_id in current_tracks: # íŠ¸ë™ ì •ë³´ê°€ ë©”ëª¨ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸
                            track = current_tracks[visible_id]
                            # í™•ì •ëœ íŠ¸ë™ì´ê³  ì™¸ëª¨ íŠ¹ì§•ì´ ìˆì„ ê²½ìš°
                            if track.is_confirmed() and track.features:
                                dist = 1 - np.dot(track.features[-1], target_mean_feature)
                                if dist < min_dist:
                                    min_dist, best_match_id = dist, visible_id
                    
                    # ê°€ì¥ ë‹®ì€ ì‚¬ëŒì„ ì°¾ì•˜ê³ , ê·¸ ìœ ì‚¬ë„ê°€ ì„ê³„ê°’(THRESHOLD)ë³´ë‹¤ ë†’ìœ¼ë©´
                    if min_dist < REID_THRESHOLD:
                        print(f"ğŸ”„ íƒ€ê²Ÿ ì¬ì‹ë³„ ì„±ê³µ! ID {target_id} -> {best_match_id} (ê±°ë¦¬: {min_dist:.3f})")
                        target_id = best_match_id
                        target_lost_time = None  # ì¬ì‹ë³„ì— ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ë¶„ì‹¤ íƒ€ì´ë¨¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
                        re_id_succeeded = True
            
            # 3.3. ìµœì¢… lost_time ê³„ì‚°
            # target_lost_timeì— ê°’ì´ ìˆë‹¤ë©´ (ì¦‰, ë¶„ì‹¤ ìƒíƒœê°€ ì§€ì†ë˜ê³  ìˆë‹¤ë©´)
            if target_lost_time is not None:
                 lost_time = time.time() - target_lost_time

        # 4. ìƒíƒœ ì „ì†¡ ë° ì‹œê°í™”
        current_time = time.time()
        if current_time - last_status_send_time > 1.0:  # 1ì´ˆë§ˆë‹¤ ì „ì†¡
        # current_time = time.time()
            message = {'timestamp': time.time(), 'lost_time': lost_time}
            status_sock.sendto(json.dumps(message).encode(), (ROS_BRIDGE_IP, ROS_BRIDGE_PORT))
            last_status_send_time = current_time

        # í˜„ì¬ í”„ë ˆì„ì— ë³´ì´ëŠ” ëª¨ë“  ê°ì²´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        for output in tracked_outputs:
            x1, y1, x2, y2, track_id_out = map(int, output[:5])
            color = (255, 0, 0)  # ê¸°ë³¸ ìƒ‰ìƒ (íŒŒë€ìƒ‰)
            label = f"ID {track_id_out}"
            # ë§Œì•½ í˜„ì¬ ê°ì²´ê°€ ìš°ë¦¬ì˜ íƒ€ê²Ÿì´ë¼ë©´ ìƒ‰ìƒê³¼ ë¼ë²¨ì„ ë³€ê²½í•©ë‹ˆë‹¤.
            if track_id_out == target_id:
                color = (0, 255, 0)  # íƒ€ê²Ÿ ìƒ‰ìƒ (ë…¹ìƒ‰)
                label = f"TARGET: {track_id_out}"
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        # ë¶„ì‹¤ ì‹œê°„ì´ 0ë³´ë‹¤ í¬ë©´ í™”ë©´ì— "TARGET LOST" ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
        if lost_time > 0:
            cv2.putText(frame, f"TARGET LOST: {lost_time:.1f}s", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        cv2.imshow("Object Tracker (UDP Input)", frame)
        # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë£¨í”„ë¥¼ íƒˆì¶œí•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    # Ctrl+Cë¥¼ ëˆŒëŸ¬ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•  ë•Œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    print("\n[ì¢…ë£Œ] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
finally:
    # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í•­ìƒ ì‹¤í–‰ë˜ëŠ” ì½”ë“œë¡œ, ìì›ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    print("ì†Œì¼“ì„ ë‹«ê³  í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    image_sock.close()
    status_sock.close()
    cmd_sock.close()
    cv2.destroyAllWindows()