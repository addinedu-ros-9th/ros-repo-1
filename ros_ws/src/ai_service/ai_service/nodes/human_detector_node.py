#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import rclpy
from rclpy.node import Node
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO

# ROS 2 í‘œì¤€ ì´ë¯¸ì§€ ë©”ì‹œì§€ íƒ€ì…ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from sensor_msgs.msg import Image

# ì§ì ‘ ì •ì˜í•œ ì»¤ìŠ¤í…€ ë©”ì‹œì§€ íƒ€ì…ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
# ì´ ë©”ì‹œì§€ëŠ” íƒì§€ëœ ì‚¬ëŒì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
from libo_interfaces.msg import HumanInfo

# ì‚¬ëŒ íƒì§€ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. (ë…¸ë“œ ë‚´ë¶€ìš©)
# ROS ë©”ì‹œì§€ì™€ëŠ” ë³„ê°œë¡œ, ì½”ë“œ ë‚´ì—ì„œ ë°ì´í„°ë¥¼ í¸ë¦¬í•˜ê²Œ ë‹¤ë£¨ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
class PersonDetection:
    def __init__(self):
        self.track_id = None            # YOLOv8ì´ ë¶€ì—¬í•˜ëŠ” ì¶”ì  ID
        self.x_center = 0.0             # ë°”ìš´ë”© ë°•ìŠ¤ì˜ xì¶• ì¤‘ì‹¬ ì¢Œí‘œ
        self.y_center = 0.0             # ë°”ìš´ë”© ë°•ìŠ¤ì˜ yì¶• ì¤‘ì‹¬ ì¢Œí‘œ
        self.width = 0.0                # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ë„ˆë¹„
        self.height = 0.0               # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ë†’ì´
        self.confidence = 0.0           # íƒì§€ ì‹ ë¢°ë„ (0.0 ~ 1.0)
        self.distance = 0.0             # ë¡œë´‡ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ (ë¯¸í„° ë‹¨ìœ„)
        self.horizontal_offset = 0.0    # ì´ë¯¸ì§€ ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ ìˆ˜í‰ ì˜¤í”„ì…‹ (ë¹„ìœ¨)

class HumanDetectorNode(Node):
    """
    RGB-D ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒì„ íƒì§€í•˜ê³  ì¶”ì í•˜ëŠ” ROS 2 ë…¸ë“œ.
    íƒì§€ëœ ì‚¬ëŒ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ëŒì„ íƒ€ê²Ÿìœ¼ë¡œ ì§€ì •í•˜ê³ , 
    í•´ë‹¹ íƒ€ê²Ÿì˜ ì •ë³´ë¥¼ ì»¤ìŠ¤í…€ ë©”ì‹œì§€('/human_info')ë¡œ ë°œí–‰í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        # ë…¸ë“œ ì´ë¦„ì„ 'human_detector_node'ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        super().__init__('human_detector_node')
        
        # --- 1. ì˜ì¡´ì„± ë° ëª¨ë¸ ì´ˆê¸°í™” ---
        self.bridge = CvBridge()  # ROS ì´ë¯¸ì§€ ë©”ì‹œì§€ì™€ OpenCV ì´ë¯¸ì§€ ê°„ì˜ ë³€í™˜ì„ ìœ„í•œ ë¸Œë¦¿ì§€
        self.model = YOLO('yolov8n.pt')  # YOLOv8 ê°ì²´ íƒì§€ ëª¨ë¸ ë¡œë“œ (ê°€ì¥ ì‘ì€ 'nano' ë²„ì „)
        
        # --- 2. ë‚´ë¶€ ë³€ìˆ˜ ì´ˆê¸°í™” ---
        self.rgb_image = None  # RGB ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        self.depth_image = None  # Depth ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        
        # --- 3. íƒ€ê²Ÿ ê´€ë¦¬ ë³€ìˆ˜ ---
        self.target_track_id = None  # í˜„ì¬ ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì˜ ID
        self.target_lost_count = 0  # íƒ€ê²Ÿì„ ë†“ì¹œ íšŸìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•˜ëŠ” ë³€ìˆ˜
        self.target_lost_threshold = 50  # íƒ€ê²Ÿì„ ì™„ì „íˆ ìƒì—ˆë‹¤ê³  íŒë‹¨í•˜ê¸° ìœ„í•œ ì„ê³„ê°’ (50 í”„ë ˆì„, ì•½ 5ì´ˆ)
        self.min_detection_distance = 0.3  # íƒ€ê²Ÿìœ¼ë¡œ ì¸ì‹í•  ìµœì†Œ ê±°ë¦¬ (0.3m)
        self.max_detection_distance = 5.0  # íƒ€ê²Ÿìœ¼ë¡œ ì¸ì‹í•  ìµœëŒ€ ê±°ë¦¬ (5.0m)
        
        # --- 4. íŒŒë¼ë¯¸í„° ì„¤ì • ---
        self.confidence_threshold = 0.5  # ì‚¬ëŒìœ¼ë¡œ íŒë‹¨í•  ìµœì†Œ ì‹ ë¢°ë„
        self.person_class_id = 0  # COCO ë°ì´í„°ì…‹ì—ì„œ 'person' í´ë˜ìŠ¤ì˜ IDëŠ” 0ì…ë‹ˆë‹¤.
        self.show_window = True  # ë””ë²„ê¹…ìš© ì‹œê°í™” ì°½ì„ ì¼¤ì§€ ì—¬ë¶€

        # --- 5. ROS 2 í†µì‹  ì„¤ì • ---
        
        # [ì…ë ¥] RGB ì´ë¯¸ì§€ í† í”½ì„ êµ¬ë…í•©ë‹ˆë‹¤.
        self.rgb_subscriber = self.create_subscription(
            Image, '/ascamera_nuwa/camera_publisher/rgb0/image', self.rgb_callback, 10)
        
        # [ì…ë ¥] Depth ì´ë¯¸ì§€ í† í”½ì„ êµ¬ë…í•©ë‹ˆë‹¤.
        self.depth_subscriber = self.create_subscription(
            Image, '/ascamera_nuwa/camera_publisher/depth0/image_raw', self.depth_callback, 10)
        
        # [ì¶œë ¥] íƒì§€ëœ ì‚¬ëŒì˜ ì •ë³´ë¥¼ ë°œí–‰í•  Publisherë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        self.info_publisher = self.create_publisher(HumanInfo, 'human_info', 10)
        
        # 0.1ì´ˆë§ˆë‹¤ (10Hz) ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ì¸ 'process_detection'ì„ ì‹¤í–‰í•  íƒ€ì´ë¨¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        self.timer = self.create_timer(0.1, self.process_detection)
        
        self.get_logger().info('ğŸ¤– Human Detector Node ì‹œì‘! (Custom Message Publisher)')
        self.get_logger().info("ğŸ“¢ '/human_info' í† í”½ìœ¼ë¡œ íƒì§€ëœ ì‚¬ëŒì˜ ë°ì´í„°ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤.")
        self.get_logger().info("ğŸ–¥ï¸ 'Human Detection Debug' ì°½ìœ¼ë¡œ ì‹œê°í™” ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

    def rgb_callback(self, msg):
        """RGB ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ë©´ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜."""
        try:
            # ROS ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCVì˜ BGR8 í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            self.rgb_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f'RGB ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}')
    
    def depth_callback(self, msg):
        """Depth ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ë©´ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜."""
        try:
            # ROS ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCVì˜ 16ë¹„íŠ¸ ë‹¨ì¼ ì±„ë„(16UC1) í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            self.depth_image = self.bridge.imgmsg_to_cv2(msg, "16UC1")
        except Exception as e:
            self.get_logger().error(f'Depth ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}')

    def find_valid_detections(self, all_detections):
        """íƒì§€ëœ ê°ì²´ë“¤ ì¤‘ ì„¤ì •ëœ ê±°ë¦¬ ë²”ìœ„ ë‚´ì— ìˆëŠ” ìœ íš¨í•œ ê°ì²´ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤."""
        return [d for d in all_detections if self.min_detection_distance <= d.distance <= self.max_detection_distance]

    def find_closest_detection(self, detections):
        """ì£¼ì–´ì§„ ê°ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê±°ë¦¬ê°€ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        if not detections:
            return None
        return min(detections, key=lambda d: d.distance)
        
    def update_target_tracking(self, all_detections):
        """íƒ€ê²Ÿ ì¶”ì  ë¡œì§ì„ ì—…ë°ì´íŠ¸í•˜ê³  í˜„ì¬ ìƒíƒœì™€ íƒ€ê²Ÿ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        valid_detections = self.find_valid_detections(all_detections)
        
        # 1. í˜„ì¬ ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì´ ìˆëŠ” ê²½ìš°
        if self.target_track_id is not None:
            # ìœ íš¨í•œ íƒì§€ ëª©ë¡ì—ì„œ í˜„ì¬ íƒ€ê²Ÿ IDë¥¼ ì°¾ì•„ë´…ë‹ˆë‹¤.
            target_detection = next((d for d in valid_detections if d.track_id == self.target_track_id), None)
            
            if target_detection:
                # íƒ€ê²Ÿì„ ê³„ì† ë°œê²¬í•œ ê²½ìš°: lost ì¹´ìš´í„°ë¥¼ ë¦¬ì…‹í•˜ê³  íƒ€ê²Ÿ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                self.target_lost_count = 0
                return "TARGET_TRACKED", target_detection
            else:
                # íƒ€ê²Ÿì„ ë†“ì¹œ ê²½ìš°: lost ì¹´ìš´í„°ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
                self.target_lost_count += 1
                if self.target_lost_count >= self.target_lost_threshold:
                    # ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ íƒ€ê²Ÿì„ ì™„ì „íˆ ìƒì—ˆë‹¤ê³  íŒë‹¨í•˜ê³  íƒ€ê²Ÿ ì •ë³´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                    self.target_track_id = None
                    self.target_lost_count = 0
                    return "TARGET_LOST", None
                else:
                    # ì•„ì§ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´, íƒ€ê²Ÿì´ ë‹¤ì‹œ ë‚˜íƒ€ë‚˜ê¸¸ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
                    return "TARGET_WAITING", None
        
        # 2. í˜„ì¬ ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì´ ì—†ëŠ” ê²½ìš°
        if valid_detections:
            # ìœ íš¨í•œ íƒì§€ ëª©ë¡ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ë¥¼ ìƒˆë¡œìš´ íƒ€ê²Ÿìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
            new_target = self.find_closest_detection(valid_detections)
            if new_target and new_target.track_id is not None:
                self.target_track_id = new_target.track_id
                self.target_lost_count = 0
                return "TARGET_ACQUIRED", new_target
                
        # 3. ìœ íš¨í•œ íƒì§€ ê°ì²´ê°€ ì•„ë¬´ë„ ì—†ëŠ” ê²½ìš°
        return "NO_TARGET", None
        
    def calculate_distance(self, x, y):
        """ì£¼ì–´ì§„ ì¢Œí‘œ (x, y)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ 5x5 ì˜ì—­ì˜ í‰ê·  ê¹Šì´ ê°’ì„ ê³„ì‚°í•˜ì—¬ ê±°ë¦¬(m)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.depth_image is None:
            return 0.0
        h, w = self.depth_image.shape
        # ì¢Œí‘œê°€ ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        if 0 <= y < h and 0 <= x < w:
            # ì¤‘ì‹¬ì  ì£¼ë³€ì˜ 5x5 ì˜ì—­ì„ ì„¤ì •í•©ë‹ˆë‹¤. (ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë„˜ì§€ ì•Šë„ë¡)
            x_start, x_end = max(0, x - 2), min(w, x + 3)
            y_start, y_end = max(0, y - 2), min(h, y + 3)
            
            # í•´ë‹¹ ì˜ì—­ì˜ ê¹Šì´ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            depth_region = self.depth_image[y_start:y_end, x_start:x_end]
            
            # ê¹Šì´ ê°’ì´ 0ì¸ ê²½ìš°(ì¸¡ì • ì‹¤íŒ¨)ë¥¼ ì œì™¸í•˜ê³  ìœ íš¨í•œ ê°’ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
            valid_depths = depth_region[depth_region > 0]
            
            if len(valid_depths) > 0:
                # ìœ íš¨í•œ ê¹Šì´ ê°’ë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ê³ , mm ë‹¨ìœ„ë¥¼ m ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
                return np.mean(valid_depths) / 1000.0
        return 0.0
    
    def draw_detection(self, image, detection, is_target=False):
        """í•˜ë‚˜ì˜ íƒì§€ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ì‹œê°ì ìœ¼ë¡œ ê·¸ë¦½ë‹ˆë‹¤ (ë°”ìš´ë”© ë°•ìŠ¤, ì •ë³´ í…ìŠ¤íŠ¸)."""
        if is_target:
            # íƒ€ê²Ÿì¸ ê²½ìš°: ìí™ìƒ‰, ë” ë‘êº¼ìš´ ì„ ìœ¼ë¡œ í‘œì‹œ
            base_color = (255, 0, 255) 
            thickness = 3
            text_prefix = f"TARGET[{detection.track_id}]: "
        else:
            # ì¼ë°˜ íƒì§€ì¸ ê²½ìš°: ë…¹ìƒ‰, ì¼ë°˜ ë‘ê»˜ë¡œ í‘œì‹œ
            base_color = (0, 255, 0)
            thickness = 2
            text_prefix = f"ID[{detection.track_id}]: "

        # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œìƒë‹¨(x1, y1)ê³¼ ìš°í•˜ë‹¨(x2, y2) ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        x1 = int(detection.x_center - detection.width / 2)
        y1 = int(detection.y_center - detection.height / 2)
        x2 = int(detection.x_center + detection.width / 2)
        y2 = int(detection.y_center + detection.height / 2)
        
        # ì‚¬ê°í˜•ì„ ê·¸ë¦½ë‹ˆë‹¤.
        cv2.rectangle(image, (x1, y1), (x2, y2), base_color, thickness)
        
        # í‘œì‹œí•  í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤ (ID, ê±°ë¦¬, ìˆ˜í‰ ìœ„ì¹˜).
        text = f'{text_prefix}{detection.distance:.2f}m | Pos:{detection.horizontal_offset:+.2f}'
            
        # í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°°ê²½ ì‚¬ê°í˜•ì„ ê·¸ë¦½ë‹ˆë‹¤.
        (w, h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        cv2.rectangle(image, (x1, y1 - h - 10), (x1 + w, y1), base_color, -1)
        # í…ìŠ¤íŠ¸ë¥¼ ì”ë‹ˆë‹¤.
        cv2.putText(image, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    def draw_status_info(self, image, tracking_status, target_detection):
        """ì´ë¯¸ì§€ ì¢Œì¸¡ ìƒë‹¨ì— í˜„ì¬ ë…¸ë“œì˜ ì „ë°˜ì ì¸ ìƒíƒœ ì •ë³´ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."""
        status_text = f'Status: {tracking_status}'
        if target_detection:
            status_text += f' (Target ID: {target_detection.track_id})'
        
        cv2.putText(image, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

    def process_detection(self):
        """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜: 10Hzë¡œ ì‹¤í–‰ë˜ë©°, íƒì§€, ì¶”ì , ë°œí–‰, ì‹œê°í™”ì˜ ì „ì²´ ê³¼ì •ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤."""
        if self.rgb_image is None:
            # ì•„ì§ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì‹ í•˜ì§€ ëª»í–ˆë‹¤ë©´ í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
            return

        # ì‹œê°í™”ë¥¼ ìœ„í•´ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤.
        debug_image = self.rgb_image.copy()
            
        # --- 1. ì‚¬ëŒ íƒì§€ ë° ì •ë³´ ì¶”ì¶œ ---
        # YOLOv8 ëª¨ë¸ë¡œ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. persist=TrueëŠ” í”„ë ˆì„ ê°„ ì¶”ì  ì •ë³´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        results = self.model.track(self.rgb_image, persist=True, verbose=False)
        h, w, _ = self.rgb_image.shape
        image_center_x = w // 2
        
        all_detections = [] # ì´ë²ˆ í”„ë ˆì„ì—ì„œ íƒì§€ëœ ëª¨ë“  ì‚¬ëŒ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        if results and results[0].boxes:
            for box in results[0].boxes:
                # 'person' í´ë˜ìŠ¤ì´ê³  ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                if int(box.cls[0]) == self.person_class_id and float(box.conf[0]) >= self.confidence_threshold:
                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2
                    
                    # PersonDetection ê°ì²´ë¥¼ ìƒì„±í•˜ê³  íƒì§€ ì •ë³´ë¥¼ ì±„ì›ë‹ˆë‹¤.
                    detection = PersonDetection()
                    detection.track_id = int(box.id[0]) if box.id is not None else -1
                    detection.confidence = float(box.conf[0])
                    detection.x_center = float(center_x)
                    detection.y_center = float(center_y)
                    detection.width = float(x2 - x1)
                    detection.height = float(y2 - y1)
                    detection.distance = self.calculate_distance(center_x, center_y)
                    detection.horizontal_offset = (center_x - image_center_x) / image_center_x if image_center_x > 0 else 0.0
                    all_detections.append(detection)

        # --- 2. íƒ€ê²Ÿ ì¶”ì  ë° ë°œí–‰í•  ë°ì´í„° ê²°ì • ---
        tracking_status, target_detection = self.update_target_tracking(all_detections)
        
        # ë°œí–‰í•  HumanInfo ë©”ì‹œì§€ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        human_info_msg = HumanInfo()
        
        if target_detection:
            # ì¶”ì  ì¤‘ì¸ íƒ€ê²Ÿì´ ìˆìœ¼ë©´, íƒ€ê²Ÿì˜ ì •ë³´ë¡œ ë©”ì‹œì§€ë¥¼ ì±„ì›ë‹ˆë‹¤.
            human_info_msg.is_detected = True
            human_info_msg.track_id = target_detection.track_id
            human_info_msg.confidence = target_detection.confidence
            human_info_msg.distance = target_detection.distance
            human_info_msg.horizontal_offset = target_detection.horizontal_offset
        else:
            # íƒ€ê²Ÿì´ ì—†ìœ¼ë©´, 'íƒì§€ ì•ˆë¨' ìƒíƒœë¡œ ë©”ì‹œì§€ë¥¼ ì±„ì›ë‹ˆë‹¤.
            human_info_msg.is_detected = False
            human_info_msg.track_id = -1
            human_info_msg.confidence = 0.0
            human_info_msg.distance = 0.0
            human_info_msg.horizontal_offset = 0.0

        # --- 3. HumanInfo ë©”ì‹œì§€ ë°œí–‰ ---
        self.info_publisher.publish(human_info_msg)
        
        # --- 4. ì‹œê°ì  ë””ë²„ê¹… ---
        if self.show_window:
            # ëª¨ë“  íƒì§€ëœ ì‚¬ëŒì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
            for det in all_detections:
                is_target = (target_detection is not None and det.track_id == target_detection.track_id)
                self.draw_detection(debug_image, det, is_target)
            
            # í˜„ì¬ ì¶”ì  ìƒíƒœ ì •ë³´ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
            self.draw_status_info(debug_image, tracking_status, target_detection)

            # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì°½ì— í‘œì‹œí•©ë‹ˆë‹¤.
            cv2.imshow('Human Detection Debug', debug_image)
            key = cv2.waitKey(1) & 0xFF
            # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.
            if key == ord('q'):
                self.get_logger().info('ğŸ‘‹ Qí‚¤ë¡œ ì¢…ë£Œ ìš”ì²­ë¨')
                rclpy.shutdown()

def main(args=None):
    # ROS 2 ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    rclpy.init(args=args)
    # HumanDetectorNode ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    node = HumanDetectorNode()
    try:
        # ë…¸ë“œë¥¼ ì‹¤í–‰í•˜ê³  ì½œë°± í•¨ìˆ˜ë“¤ì´ í˜¸ì¶œë˜ë„ë¡ ëŒ€ê¸°í•©ë‹ˆë‹¤.
        rclpy.spin(node)
    except KeyboardInterrupt:
        # Ctrl+C ì…ë ¥ ì‹œ, ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
        pass
    finally:
        # ë…¸ë“œê°€ ì¢…ë£Œë  ë•Œ ëª¨ë“  OpenCV ì°½ì„ ë‹«ìŠµë‹ˆë‹¤.
        cv2.destroyAllWindows()
        # rclpyë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.
        if rclpy.ok():
            node.destroy_node()
            rclpy.shutdown()

if __name__ == '__main__':
    # ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    main()